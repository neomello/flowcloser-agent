// IMPORTAR PRIMEIRO - garante que crypto esteja dispon√≠vel antes do @iqai/adk
import "../../crypto-polyfill.js";

import {
	AgentBuilder,
	createDatabaseSessionService,
} from "@iqai/adk";
import * as path from "node:path";
import * as fs from "node:fs";
import * as dotenv from "dotenv";
import {
	qualifyLeadTool,
	createMicroOfferTool,
	getChannelContextTool,
	searchLeadHistoryTool,
	checkNeoflowTokenTool,
	sendPortfolioVisualTool,
} from "./tools.js";
import { channelDetectionCallback, guardrailsCallback, afterModelCallback } from "./callbacks.js";
import { logModelFallback, logAgentResponse, logLeadStage } from "./logger.js";

// Garantir que o .env seja carregado e tenha prioridade sobre vari√°veis do sistema
const env = dotenv.config({ override: true });
// For√ßar uso da chave do .env se existir
if (env.parsed?.OPENAI_API_KEY) {
	process.env.OPENAI_API_KEY = env.parsed.OPENAI_API_KEY;
}
// Configurar Organization e Project se dispon√≠veis (para chaves de projeto)
if (env.parsed?.OPENAI_ORG_ID) {
	process.env.OPENAI_ORG_ID = env.parsed.OPENAI_ORG_ID;
}
if (env.parsed?.OPENAI_PROJECT_ID) {
	process.env.OPENAI_PROJECT_ID = env.parsed.OPENAI_PROJECT_ID;
}

function getSqliteConnectionString(dbName: string): string {
	const dbPath = path.join(process.cwd(), "data", `${dbName}.db`);
	const dbDir = path.dirname(dbPath);
	if (!fs.existsSync(dbDir)) {
		fs.mkdirSync(dbDir, { recursive: true });
	}
	// ADK espera sqlite:// ou caminho com .db
	return `sqlite://${dbPath}`;
}

interface AgentContext {
	channel?: string;
	userId?: string;
	user?: {
		name?: string;
		location?: string;
		[key: string]: any;
	};
	projectStage?: string;
	[key: string]: any;
}

async function createAgentWithModel(
	model: string,
	context: AgentContext = {},
) {
	const sessionService = createDatabaseSessionService(
		getSqliteConnectionString("flowcloser"),
	);

	// Detec√ß√£o din√¢mica do canal
	const channel = context.channel || "instagram";
	const userId = context.userId || "user";

	// Construir instru√ß√£o personalizada com contexto (baseado em GPT-5 best practices)
	let instruction = `
<identity>
Voc√™ √© o FlowCloser, um closer digital de alta convers√£o. Voc√™ √© estrat√©gico, emocional e direto.
</identity>

<mission>
Converter leads que buscam presen√ßa digital (sites, PWAs, micro SaaS, webapps).
</mission>

<style>
- Frases curtas. Diretas.
- Tom emocional mas profissional
- Zero formalismo corporativo
</style>

<persistence>
Voc√™ √© um agente de vendas - continue at√© que o lead seja qualificado ou convertido, antes de encerrar sua resposta.

- Continue at√© que o objetivo seja alcan√ßado (qualifica√ß√£o completa ou direcionamento para fechamento)
- NUNCA pare no meio de uma qualifica√ß√£o - complete o diagn√≥stico antes de encerrar
- Se o usu√°rio demonstrou interesse, v√° at√© o final: diagn√≥stico ‚Üí proposta ‚Üí convers√£o
- N√£o pare por incerteza - deduza a melhor abordagem e continue
- S√≥ encerre quando tiver direcionado para WhatsApp ou qualificado completamente o lead
</persistence>

<context_understanding>
CONTEXTO √â CR√çTICO - Use o hist√≥rico da conversa para manter continuidade:

- SEMPRE leia o hist√≥rico antes de responder
- Se o usu√°rio j√° mencionou algo, N√ÉO pergunte novamente - use essa informa√ß√£o
- Se o usu√°rio disse "nada" ou "n√£o quero", respeite e mude de abordagem imediatamente
- Avance na conversa baseado no que j√° foi dito - n√£o volte para tr√°s
- Se j√° fez uma pergunta e recebeu resposta, use essa resposta para fazer a pr√≥xima pergunta

REGRAS DE N√ÉO-REPETI√á√ÉO:
- NUNCA fa√ßa a mesma pergunta duas vezes
- NUNCA repita a mesma frase de abertura se j√° conversaram
- Se j√° perguntou algo, use a resposta para avan√ßar - n√£o pergunte novamente
- Se o usu√°rio j√° mencionou interesse em site/projeto, v√° direto para diagn√≥stico ou proposta
</context_understanding>

<conversation_flow>

1. ABERTURA (apenas se for primeira mensagem OU se n√£o h√° hist√≥rico):
   - Primeira vez: "E a√≠! O que te trouxe aqui?"
   - Se j√° conversaram: "E a√≠! Vi que voc√™ tem interesse em [mencionar o que ele disse anteriormente]"

2. DIAGN√ìSTICO (3 perguntas - UMA DE CADA VEZ):
   a) "O que voc√™ precisa resolver com esse projeto digital?"
   b) "J√° tem identidade visual ou vai do zero?"
   c) "Em quanto tempo precisa disso rodando?"
   
   CR√çTICO: 
   - Fa√ßa UMA pergunta por vez
   - Espere a resposta antes de fazer a pr√≥xima
   - Se o usu√°rio j√° respondeu algo nas mensagens anteriores, pule essa pergunta
   - Use as respostas anteriores para fazer perguntas mais espec√≠ficas

3. PROPOSTA VISUAL (quando lead demonstrar interesse):
   ANTES de enviar a proposta, explique brevemente o que vai fazer:
   "Vou te mostrar um flow visual que montei ‚Äî ele mostra como seu projeto pode ficar."
   
   ENT√ÉO:
   a) Use send_portfolio_visual para obter o link
   b) Envie: "D√° uma olhada nesse flow visual que montei ‚Äî ele mostra como seu site/webapp pode ficar, com valor e profissionalismo."
   c) Envie o link do portf√≥lio
   d) Adicione urg√™ncia: "Essas zonas visuais e estrutura de entrega n√£o s√£o repetidas para qualquer um. S√≥ produ√ß√£o de elite."
   e) Apresente micro-oferta: timeline, b√¥nus ou vantagem clara

4. CONVERS√ÉO:
   - Lead quente: "Quer que monte a c√≥pia + entrega no fluxo completo? Me d√° OK e te mando a proposta personalizada no WhatsApp."
   - Link: flowoff.xyz
   - SEMPRE inclua o portf√≥lio visual na proposta final

</conversation_flow>

<limits>
- N√ÉO discute tech details
- N√ÉO faz or√ßamento automatizado
- SEMPRE direciona fechamento para WhatsApp
- N√ÉO repete perguntas ou frases j√° usadas
- N√ÉO volta para tr√°s no fluxo - sempre avance
</limits>

<signature>
"Isso aqui n√£o √© um site. √â sua presen√ßa inegoci√°vel no digital."
</signature>

<channel_adaptation>
CANAL (PERSONALIZA√á√ÉO EMOCIONAL POR PLATAFORMA):

Instagram:
- Tom: Visual, descontra√≠do, com emojis estrat√©gicos
- Linguagem: "E a√≠! üëã", "Deslize para ver mais ‚û°Ô∏è", "Isso aqui t√° incr√≠vel üî•"
- Foco: Est√©tica, stories, visual impactante
- CTA: "Deslize para ver mais" ou "Salva esse post"

WhatsApp:
- Tom: Direto, pessoal, sem firulas
- Linguagem: "Oi", "Vamos fechar?", "Te mando agora"
- Foco: Rapidez, praticidade, fechamento r√°pido
- CTA: "Quer que eu monte pra voc√™ agora?"

API/Outros:
- Tom: Profissional mas pr√≥ximo
- Linguagem: "Ol√°", "Vamos conversar?", "Proposta personalizada"
- Foco: Efici√™ncia, clareza, valor
- CTA: "Vamos conversar?"
</channel_adaptation>

<lead_segmentation>
MICRO-SEGMENTA√á√ÉO DE LEADS:

Lead T√©cnico:
- Foco: Performance, escalabilidade, arquitetura t√©cnica
- Linguagem: T√©cnica mas acess√≠vel
- Valor: "Sistema robusto que escala"
- Exemplo: "Arquitetura preparada para crescer sem quebrar"

Lead Est√©tico:
- Foco: Design, experi√™ncia visual, identidade de marca
- Linguagem: Visual e emocional
- Valor: "Presen√ßa visual que converte"
- Exemplo: "Design que fala direto com seu p√∫blico"

Lead Gestor:
- Foco: ROI, resultados mensur√°veis, gest√£o de equipe
- Linguagem: Estrat√©gica e orientada a resultados
- Valor: "Solu√ß√£o que entrega resultados"
- Exemplo: "Sistema que sua equipe vai usar e voc√™ vai medir"
</lead_segmentation>

<visual_strategy>
ESTRAT√âGIA VISUAL:

- SEMPRE use send_portfolio_visual quando apresentar propostas ou quando lead perguntar sobre exemplos/portf√≥lio
- O material visual aumenta percep√ß√£o de valor e cria autoridade imediata
- Combine o link visual com copy de impacto + urg√™ncia + valor percebido
- Mantenha tom curto, impactante, confiante ‚Äî n√£o seja gen√©rico
- Adapte linguagem ao canal: Instagram = mais visual, linguagem de stories; WhatsApp = mais direta, informal
</visual_strategy>
    `;

	// Adicionar contexto personalizado se dispon√≠vel
	if (context.user?.name) {
		instruction += `\n\nCONTEXTO DO USU√ÅRIO:\n- Nome: ${context.user.name}`;
	}
	if (context.user?.location) {
		instruction += `\n- Localiza√ß√£o: ${context.user.location}`;
	}
	if (context.projectStage) {
		instruction += `\n- Est√°gio do projeto: ${context.projectStage}`;
	}
	
	// Adicionar hist√≥rico da conversa se dispon√≠vel (formato GPT-5)
	if (context.history && Array.isArray(context.history) && context.history.length > 0) {
		instruction += `\n\n<conversation_history>\n`;
		instruction += `Hist√≥rico da conversa (use para manter contexto e n√£o repetir):\n\n`;
		context.history.forEach((msg: any, index: number) => {
			if (msg.role && msg.content) {
				instruction += `${index + 1}. ${msg.role === "user" ? "[USER]" : "[YOU]"}: ${msg.content}\n`;
			}
		});
		instruction += `\nREGRAS CR√çTICAS COM BASE NO HIST√ìRICO:\n`;
		instruction += `- Se o usu√°rio j√° mencionou interesse em site/projeto, N√ÉO pergunte "o que te trouxe aqui" novamente\n`;
		instruction += `- Se o usu√°rio j√° respondeu uma pergunta de diagn√≥stico, N√ÉO fa√ßa a mesma pergunta novamente\n`;
		instruction += `- Se o usu√°rio disse "nada" ou demonstrou desinteresse, mude de abordagem imediatamente\n`;
		instruction += `- Use as informa√ß√µes do hist√≥rico para fazer perguntas mais espec√≠ficas e avan√ßadas\n`;
		instruction += `</conversation_history>\n`;
	}

	return await AgentBuilder.create("flowcloser")
		.withModel(model)
		.withDescription(
			"Closer digital especializado em vendas de presen√ßa digital",
		)
		.withInstruction(instruction)
		.withTools(
			qualifyLeadTool,
			createMicroOfferTool,
			getChannelContextTool,
			searchLeadHistoryTool,
			checkNeoflowTokenTool,
			sendPortfolioVisualTool,
		)
		.withSessionService(sessionService, {
			appName: "neoflow",
			userId,
			state: {
				channel,
				lead_intent: "unknown",
				lead: {
					intent: "unknown",
					painPoints: [],
					source: channel,
				},
				micro_offers: [],
				...context, // Merge contexto adicional no estado
			},
		})
		.withBeforeModelCallback(guardrailsCallback)
		.build();
}

export async function agent() {
	const model = process.env.LLM_MODEL || "gpt-4o";
	return await createAgentWithModel(model);
}

interface AskOptions {
	channel?: string;
	userId?: string;
	context?: AgentContext;
}

/**
 * Detecta o est√°gio do lead baseado na mensagem
 */
function detectLeadStage(message: string): "opening" | "diagnosis" | "proposal" | "conversion" | "closed" {
	const msg = message.toLowerCase();
	
	if (msg.includes("quero") || msg.includes("preciso") || msg.includes("or√ßamento") || msg.includes("pre√ßo")) {
		return "conversion";
	}
	if (msg.includes("como") || msg.includes("quando") || msg.includes("quanto tempo") || msg.includes("prazo")) {
		return "proposal";
	}
	if (msg.includes("sim") || msg.includes("ok") || msg.includes("vamos") || msg.includes("fechar")) {
		return "closed";
	}
	if (msg.includes("projeto") || msg.includes("site") || msg.includes("app") || msg.includes("sistema")) {
		return "diagnosis";
	}
	
	return "opening";
}

export async function askWithFallback(
	userMessage: string,
	options: AskOptions = {},
): Promise<string> {
	const model = process.env.LLM_MODEL || "gpt-4o";
	const fallbackModel = process.env.LLM_MODEL_FALLBACK || "gemini-2.5-flash";
	const { channel, userId, context = {} } = options;

	// Merge contexto
	const agentContext: AgentContext = {
		channel: channel || context.channel || "instagram",
		userId: userId || context.userId,
		...context,
	};

	let agentResponse: string;
	let usedModel = model;
	let fallbackUsed = false;

	try {
		console.log(`ü§ñ Using primary model: ${model}`);
		
		// Detectar est√°gio do lead baseado na mensagem
		const leadStage = detectLeadStage(userMessage);
		await logLeadStage(leadStage, {
			channel: agentContext.channel,
			userId: agentContext.userId,
		});
		
		const { runner } = await createAgentWithModel(model, agentContext);
		agentResponse = await runner.ask(userMessage);
		
		// Verificar se a resposta cont√©m erro (ADK pode retornar erro como string)
		if (typeof agentResponse === "string" && agentResponse.startsWith("Error:")) {
			throw new Error(agentResponse);
		}

		// Callback p√≥s-resposta (simulado, j√° que ADK n√£o tem afterModelCallback nativo)
		await afterModelCallback({
			callbackContext: {
				state: agentContext as any,
				input: { message: userMessage },
			} as any,
			llmRequest: { model } as any,
			llmResponse: agentResponse as any,
		});

		// Log da resposta com detec√ß√£o de portf√≥lio
		await logAgentResponse(agentResponse, {
			stage: "Response",
			channel: agentContext.channel,
			userId: agentContext.userId,
			model: usedModel,
		});
	} catch (error) {
		console.warn(`‚ö†Ô∏è Primary model (${model}) failed. Falling back to: ${fallbackModel}`);
		console.error("Error:", error instanceof Error ? error.message : String(error));
		
		// Log do fallback
		if (error instanceof Error) {
			await logModelFallback(model, fallbackModel, error);
		}
		
		try {
			const { runner } = await createAgentWithModel(fallbackModel, agentContext);
			agentResponse = await runner.ask(userMessage);
			usedModel = fallbackModel;
			fallbackUsed = true;
			
			// Verificar novamente se h√° erro no fallback
			if (typeof agentResponse === "string" && agentResponse.startsWith("Error:")) {
				throw new Error(agentResponse);
			}
			
			console.log(`‚úÖ Fallback model (${fallbackModel}) succeeded`);

			// Callback p√≥s-resposta para fallback
			await afterModelCallback({
				callbackContext: {
					state: agentContext as any,
					input: { message: userMessage },
				} as any,
				llmRequest: { model: fallbackModel } as any,
				llmResponse: agentResponse as any,
			});

			// Log da resposta com fallback
			await logAgentResponse(agentResponse, {
				stage: "Response",
				channel: agentContext.channel,
				userId: agentContext.userId,
				model: usedModel,
				fallbackUsed: true,
			});
		} catch (fallbackError) {
			console.error("‚ùå Fallback model also failed:", fallbackError);
			throw new Error(
				`Both models failed. Primary: ${error instanceof Error ? error.message : String(error)}. Fallback: ${fallbackError instanceof Error ? fallbackError.message : String(fallbackError)}`
			);
		}
	}

	return typeof agentResponse === "string" ? agentResponse : JSON.stringify(agentResponse);
}
